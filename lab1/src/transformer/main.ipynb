{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fefd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "input_path = Path(\"../../datasets/wolne_lektury_corpus_cleaned.jsonl\")\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "buf = io.StringIO()\n",
    "docs = 0\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "        text = obj.get(\"text\")\n",
    "        if not text:\n",
    "            continue\n",
    "        buf.write(text)\n",
    "        buf.write(\"\\n\\n\")\n",
    "        docs += 1\n",
    "\n",
    "concatenated_text = buf.getvalue()\n",
    "tokens = enc.encode(concatenated_text)\n",
    "\n",
    "print(f\"Total characters: {len(concatenated_text):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(tokens, dtype=torch.long)\n",
    "\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 8\n",
    "train_data[: BLOCK_SIZE + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df17663",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:BLOCK_SIZE]\n",
    "y = train_data[1 : BLOCK_SIZE + 1]\n",
    "\n",
    "for t in range(BLOCK_SIZE):\n",
    "    context = x[: t + 1]\n",
    "    target = y[t]\n",
    "    print(f\"Input -> {context.tolist()}, Target -> {target.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "BLOCK_SIZE = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - BLOCK_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([data[i : i + BLOCK_SIZE] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + BLOCK_SIZE + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"xb:\", xb.shape)\n",
    "print(\"yb:\", yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98459f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(BATCH_SIZE):\n",
    "    for t in range(BLOCK_SIZE):\n",
    "        context = xb[b, : t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"b{b} t{t}: Input -> {context.tolist()}, Target -> {target.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computational-linguistics (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
